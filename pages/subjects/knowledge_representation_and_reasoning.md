<div class="divSummary">
<h2 class="verticalText">Summary</h2>
<ul class="summary">
    <li><a href="#introduction">Introduction</a></li>
        <li><a href="#unit1-activity">Unit 1 Activity</a>
        </li>
        <li><a href="#colab-1">Collaborative Learning Discussion 1</a>
            <ul class="sect">
                <li><a href="#colab-11">Peer feedback</a></li>
                <li><a href="#colab-12">Summary post</a></li>
            </ul>
        </li>
        <li><a href="#unit2-seminar-prep">Unit 2 Seminar Preparation</a>
        </li>
        <li><a href="#unit3-activity">Unit 3 Activity</a>
        </li>
        <li><a href="#unit4-seminar-prep">Unit 4 Seminar Preparation</a>
        </li>
        <li><a href="#unit5-activity">Unit 5 Activity</a>
        </li>
        <li><a href="#unit6-activity">Unit 6 Activity</a>
        </li>
        <li><a href="#reflective-piece1">Mid-Module Reflective Piece</a>
        </li>
        <li><a href="#assess1">Assessment: Case Study Review</a>
            <ul class="sect">
                <li><a href="#assess1-feedback">Tutor feedback</a></li>
            </ul>
        </li>
        <li><a href="#unit8-activity">Unit 8 Activity</a>
        </li>
        <li><a href="#colab-2">Collaborative Learning Discussion 2</a>
            <ul class="sect">
                <li><a href="#colab-21">Peer feedback</a></li>
                <li><a href="#colab-22">Summary post</a></li>
            </ul>
        </li>
        <li><a href="#unit10-activity">Unit 10 Activity</a>
        </li>
        <li><a href="#assess2">Assessment: AI Solution Implementation</a>
            <ul class="sect">
                <li><a href="#assess2-feedback">Tutor feedback</a></li>
            </ul>
        </li>
        <li><a href="#assess-outcome">Learning Outcome: Soft and Hard Skills in Business</a>
        </li>
        <li><a href="#reflection">Reflective Piece</a>
        </li>
</div>

<main class="summaryContent">
<div class="swiper mySwiper">
  <div class="swiper-wrapper">
    <div class="swiper-slide">
        <h2 id="introduction">Introduction</h2>
            <p>With Dr. Samuel Danso as our tutor, the "Knowledge Representation and Reasoning" module added more depth to students' understanding of artificial intelligence (AI) by exploring the very concept of representing the reasoning process exhibited by intelligent systems. It delved into topics such as ontology, set theory, and logic programming, some concepts that are often overlooked in AI but have proven important throughout its history, especially for symbolic computing. The module was instrumental in equipping students not only with practical and theoretical skills, but also the necessary mindset to engage in mature critical discussions with one another and stimulating us to explore this fascinating topic.</p><br><br>


        <h2 id="unit1-activity">Unit 1 Activity</h2>
            <p>The first module activity consisted of addressing the following questions:<br><br>

            "<i>Look at the seven topics described briefly below. Which of them would you consider yourself as 'knowing', and which would you consider yourself as having information about?<br><br>

            a) A second language in which you are fluent.<br>
            b) The content of a television news programme.<br>
            c) A close friend.<br>
            d) A company's annual report.<br>
            e) Your close friend's partner whom you have yet to meet.<br>
            f) The weather on the other side of the world.<br>
            g) The weather where you are now.<br><br>

            What would you suggest is the primary characteristic that distinguishes the 'having information' situations from the 'knowing' situations you categorised in the previous activity? You will need to make sure that your description does not simply describe information or data but must particularly take account of the former."</i><br><br>

            For the first question, I believe that a) and c) constitute what I "know", and b), d), e), f) and g) constitute what I have information about. For the second question, the primary characteristic that distinguishes between "having information" and "knowing" is, to me, the following:<br><br>

            <b>Knowing:</b> You have an intrinsic knowledge of the subject in question, acquired through personal experiences and observations. It is internalised in you and does not depend on external factors. In essence, you alone hold dominion over what you know.<br>
            <b>Having information:</b> The knowledge is presented to you by a third party, such as an app, news channel or someone you know. It does not come from your own efforts and thus is not internalised, while also being influenced by external factors. In essence, it may be temporal information that is subjected to rules beyond your control.</p><br><br>


        <h2 id="colab-1">Collaborative Learning Discussion 1</h2>
            <p>The first collaborative learning discussion served as a way for students to warm up to the module by discussing one of AI's peripheral themes. For it, we had the following topic to elaborate on:<br><br>
            
            "<i>Read the paper by Weststeijn, T. (2011) and then join the collaborative discussion below.<br><br>

            Knowledge Representation is a recent phenomenon - it only became a topic of discussion with the development of computing technology and the need to represent knowledge in computer systems.<br><br>

            a. Discuss this assertion. Do you agree or disagree with this opinion? Justify your position, supported with at least two academics references.<br>

            b. How is reasoning related to knowledge representation (KR)? Is KR still useful without reasoning support? Justify your answer supported by two academic references."</i><br><br>

            Students were required to create an initial post and, then, address at least 3 of their peers' submissions before creating a summary post. This final entry would serve as an evolved version of a student's initial post, incorporating peer responses and directly addressing them by either agreeing or not and providing the reasons for either case. My initial post, "Psychology, Logic, And Knowledge Representation", was as follows:<br><br>
            
            <center><img src="img/knowledge_repr_and_reasoning/initial_post.png" height="600" width="1200"><br>

            <font size="2">Figure 1: My initial post in the first collaborative learning discussion forum</font></center></p><br><br>

            
            <h3 id="colab-11"><br>Peer feedback</h3>
                <p>The peer responses from James Adams, Zhu Zhang, and Jaafar El Komati were instrumental in building upon my initial post. For James, his response was as follows:<br><br>
                
                <center><img src="img/knowledge_repr_and_reasoning/james_response.png" height="550" width="1100"><br>

                <font size="2">Figure 2: James' peer response to my initial post</font></center><br><br></font></center><br><br>
                
                As for Zhu, his response was:<br><br>
                
                <center><img src="img/knowledge_repr_and_reasoning/zhu_response.png" height="350" width="950"><br>

                <font size="2">Figure 3: Zhu's peer response to my initial post</font></center></p><br><br>

                Finally, Jaafar's response was:<br><br>
                
                <center><img src="img/knowledge_repr_and_reasoning/jaafar_response.png" height="500" width="1100"><br>

                <font size="2">Figure 4: Jaafar's peer response to my initial post</font></center></p><br><br>


            <h3 id="colab-12"><br>Summary post</h3>
                <p>My initial entry was significantly enhanced by my peers' feedback. Their comments were addressed by my summary post, which was as follows:<br><br>

                <center><img src="img/knowledge_repr_and_reasoning/summary_post_disc1.png" height="600" width="1100"><br>
                
                <font size="2">Figure 5: My summary post in the first discussion forum</font></center></p><br><br>

            
        <h2 id="unit2-seminar-prep"><br>Unit 2 Seminar Preparation</h2>
            <p>The second seminar activity consisted of answering the following questions on truth tables and logic:<br><br>

            "<i>1. Read Partee et al (1993) Chapter 1 and then attempt exercises 1 and 4, located at the end of the chapter.

            2. Read the wiki at Sharma et al (2022) and then attempt the exercises below:<br>
                i. For each clause (a) - (f) below, create truth tables for each to answer the question of when each statement is false.<br>
                    a. ~P<br>
                    b. P ∧ Q<br>
                    c. P v Q<br>
                    d. P → Q<br>
                    e. P ←→ Q<br>
                    f. P → (~Q)<br><br>

                ii. Consider the statement (~Q) -> (~P).<br>
                    a. When is it false?<br>
                    b. Now consider P → Q. When is it false?<br>
                    c. Do you believe these two compound statements mean the same thing?<br>
                    d. Construct the truth table for the statement (~Q) -> (~P). Then revisit your answer to (c).<br><br>

                iii. Construct the truth table for P XOR Q.<br><br>

                iv. Construct truth tables for the following statements.<br>
                    a. ~(P ∧ Q)<br>
                    b. P v (Q ∧ R)<br>
                    c. P v (Q v R)<br>
                    d. (P v Q) v R (Compare to the previous statement.)<br>
                    e. (P → Q) ∧ (Q → P)</i>"<br><br>
                    
            Starting from exercises 1 and 4 in Partee et al. (1993), we have the following:<br><br>

            1. (X ∧ Y) ∧ (X v Y)<br>
            X ∧ Y (idempotence)<br><br>

            4. ((X ∧ X) ∧ Y) v ((X ∧ Y) ∧ Y)<br>
            ((X ∧ Y) v ((X ∧ Y) ∧ Y) (idempotence)<br>
            ((X ∧ Y) v (X ∧ (Y ∧ Y))) (associativity)<br>
            (X ∧ Y) v (X ∧ Y) (idempotence)<br>
            X ∧ Y (idempotence)<br><br>

            For exercise 2, we have:<br><br>
            
            i.a. ~P<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/p_not_p.png" height="100" width="200"><br>
                
            <font size="2">Figure 6: The truth table for ~P</font></center><br><br>

            i.b. P ∧ Q<br><br> 

            <center><img src="img/knowledge_repr_and_reasoning/p_and_q.png" height="150" width="250"><br>
                
            <font size="2">Figure 7: The truth table for P ∧ Q</font></center><br><br>

            i.c. P v Q<br><br> 

            <center><img src="img/knowledge_repr_and_reasoning/p_or_q.png" height="150" width="250"><br>
                
            <font size="2">Figure 8: The truth table for P v Q</font></center><br><br>

            i.d. P → Q<br><br> 

            <center><img src="img/knowledge_repr_and_reasoning/p_then_q.png" height="150" width="250"><br>
                
            <font size="2">Figure 9: The truth table for P → Q</font></center><br><br>

            i.e. P ←→ Q<br><br> 

            <center><img src="img/knowledge_repr_and_reasoning/p_ifandonlyif_q.png" height="150" width="250"><br>
                
            <font size="2">Figure 10: The truth table for P ←→ Q</font></center><br><br>

            i.f. P → (~Q)<br><br> 

            <center><img src="img/knowledge_repr_and_reasoning/p_then_not_q.png" height="150" width="250"><br>
                
            <font size="2">Figure 11: The truth table for P → (~Q)</font></center><br><br>

            Now, for exercise ii., we have:<br><br>

            a. The statement (~Q) -> (~P) is false when ~P is True and ~Q is False.<br>
            b. The statement P → Q is false when P is True and Q is False.<br>
            c. In essence, yes. Both P → Q and (~Q) → (~P) wield the same results, but in different order.<br>
            d. The truth table for (~Q) → (~P) is:<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/not_q_then_not_p.png" height="150" width="250"><br>
                
            <font size="2">Figure 12: The truth table for (~Q) → (~P)</font></center><br><br>

            Comparing this truth table to the one from P → Q shows that the compound statements wield the same results, though in different order.<br><br>
            
            For exercise iii., we have:<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/p_xor_q.png" height="150" width="300"><br>
                
            <font size="2">Figure 13: The truth table for P XOR Q</font></center><br><br>

            Finally, for exercise iv., we have:<br><br>

            a. ~(P ∧ Q)<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/not_p_and_q.png" height="150" width="300"><br>
                
            <font size="2">Figure 14: The truth table for ~(P ∧ Q)</font></center><br><br>

            b. P v (Q ∧ R)<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/p_or_q_and_r.png" height="250" width="500"><br>
                
            <font size="2">Figure 15: The truth table for P v (Q ∧ R)</font></center><br><br>

            c. P v (Q v R)<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/p_or_q_or_r.png" height="250" width="500"><br>
                
            <font size="2">Figure 16: The truth table for P v (Q v R)</font></center><br><br>

            d. (P v Q) v R (Compare to the previous statement.)<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/porq_or_r.png" height="250" width="500"><br>
                
            <font size="2">Figure 17: The truth table for P v (Q v R)</font></center><br><br>

            As can be seen, (P v Q) v R yields the same results as P v (Q v R). This is because (P v Q) v R = P v (Q v R) due to association.<br><br>

            e. (P → Q) ∧ (Q → P)<br><br>
            
            <center><img src="img/knowledge_repr_and_reasoning/p_then_q_and_q_then_p.png" height="150" width="550"><br>
                
            <font size="2">Figure 18: The truth table for (P → Q) ∧ (Q → P)</font></center></p><br><br>
        
        
        <h2 id="unit3-activity">Unit 3 Activity</h2>
            <p>The third module activity consisted of the following:<br><br>

            "<i><b>Activity 1</b><br>
            Attempt the following questions from the module core text:<br><br>

            Chapter 2 Question 4 - The barber's paradox.<br>
            Chapter 3 Question 4 - A Canadian variant of an old puzzle.<br><br>

            <b>Activity 2</b><br>
            Read the paper by Palomino et al (2005) and review the 'crossing problem' diagram provided in the Lecturecast.<br><br>

            Create a set of statements in first-order logic (FOL) that represent the states shown - for example you may define two functions left and right and therefore the first state could be represented as: Left(F) and left(W) and Left(G) and left(C). Define your own set of FOL statements for the entire diagram.<br>
            You have been provided with solutions to the 'crossing problem' written in Lisp (here), Prolog (here) and Maude (here). Compare your FOL clauses with the various implementations - which of the implementations provides the closest match to your FOL version?</i>"<br><br>

            The chapter 2 question 4 question consists of the following:<br><br>

            "<i>In a certain town, there are the following regulations concerning the town barber:<br><br>

            a) Anyone who does not shave himself must be shaved by the barber.<br>
            b) Whomever the barber shaves, must not shave himself.<br><br>

            Show that no barber can fulfill these requirements. That is, formulate the requirements as sentences of FOL and show that in any interpretation where the first regulation is true, the second one must be false. (This is called the barber's paradox and was formulated by Bertrand Russell.)</i>"<br><br>

            For the first sentence, its FOL equivalent can be represented as:<br><br>

            ∀x(LivesInTown(x)) → (~Shaves(x, x) → Shaves(Barber, x))<br><br>

            As for the second sentence, its FOL equivalent is:<br><br>

            ∀x(LivesInTown(x)) → (Shaves(Barber, x) → ~Shaves(x, x))<br><br>

            This is an impossible scenario because, due to these regulations, the following happens:<br><br>

            a) If the barber does not shave himself, then by the first rule, he must be shaved by a barber, which means that he must shave himself.<br>
            b) If the barber does shave himself, then by the second rule, he must not shave himself.<br><br>

            The chapter 3 question 4 consists of the following:<br><br>

            "<i>A Canadian variant of an old puzzle:<br><br>

            A traveler in remote Quebec comes to a fork in the road and does not know which way to go to get to Chicoutimi. Henri and Pierre are two local inhabitants nearby who do know the way. One of them always tells the truth, and the other one never does, but the traveler does not know which is which. Is there a single question the traveler can ask Henri (in French, of course) that will be sure to tell him which way to go?<br>

            We will formalize this problem in FOL. Assume there are only two sorts of objects in our domain: inhabitants, denoted by the constants henri and pierre; and French questions, which Henri and Pierre can answer. These questions are denoted by the following terms:<br><br>

            * gauche, which asks if the traveler should take the left branch of the fork to get to Chicoutimi;<br>
            * dit_oui(x, q), which asks if inhabitant x would answer yes to the French question q;<br>
            * dit_non(x, q), which asks if inhabitant x would answer no to the French question q.<br><br>
            
            Obviously this is a somewhat impoverished dialect of French, although a philosophically interesting one. For example, the term<br><br>
            
            dit_non(henri, dit_oui(pierre, gauche))<br><br>
            
            represents a French question that might be translated as, “Would Henri answer no if I asked him if Pierre would say yes I should go to the left to get to Chicoutimi?” The predicate symbols of our language are the following:<br><br>

            * Truth_teller(x), which holds when inhabitant x is a truth-teller;<br>
            * Answer_yes(x, q), which holds when inhabitant x will answer yes to French question q;<br>
            * True(q), which holds when the correct answer to the question q is yes;<br>
            * Go_left, which holds if the direction to get to Chicoutimi is to go left.<br><br>

            For purposes of this puzzle, these are the only constant, function, and predicate symbols.<br><br>

            (a) Write FOL sentences for each of the following:<br><br>

            * One of Henri or Pierre is a truth-teller, and one is not.<br>
            * An inhabitant will answer yes to a question if and only if he is a truth teller and the correct answer is yes, or he is not a truth teller and the correct answer is not yes.<br>
            * The gauche question is correctly answered yes if and only if the proper direction is to go is left.<br>
            * A dit_oui(x, q) question is correctly answered yes if and only if x will answer yes to question q.<br>
            * A dit_non(x, q) question is correctly answered yes if and only if x will not answer yes to q.<br><br>

            Imagine that these facts make up the entire KB of the traveler.<br><br>
            
            (b) Show that there is a ground term t such that<br><br>

            KB |= (Answer_yes(henri, t) = Go_left)<br><br>

            In other words, there is a question t that can be asked to Henri (and there is an analogous one for Pierre) that will be answered yes if and only if the proper direction to get to Chicoutimi is to go left.<br>

            (c) Show that this KB does not entail which direction to go, that is, show that there is an interpretation satisfying the KB where Go_left is true, and another one where it is false.</i>"<br><br>

            For a), we have:<br><br>

            <b>* One of Henri or Pierre is a truth-teller, and one is not.</b><br><br>

            Truth_teller(henri) ⊕ Truth_teller(pierre)<br><br>

            <b>* An inhabitant will answer yes to a question if and only if he is a truth teller and the correct answer is yes, or he is not a truth teller and the correct answer is not yes.</b><br><br>

            Answer_yes(x, q) ←→ (Truth_teller(x) ∧ True(q)) v (~Truth_teller(x) ∧ ~True(q))<br><br>

            <b>* The gauche question is correctly answered yes if and only if the proper direction is to go is left.</b><br><br>

            True(gauche) ←→ Go_left<br><br>

            <b>* A dit_oui(x, q) question is correctly answered yes if and only if x will answer yes to question q.</b><br><br>

            True(dit_oui(x, q)) ←→ Answer_yes(x, q)<br><br>

            <b>* A dit_non(x, q) question is correctly answered yes if and only if x will not answer yes to q.</b><br><br>

            True(dit_non(x, q)) ←→ ~Answer_yes(x, q)<br><br>

            As for b), we have to recall that Henri can speak the truth as a truth-teller or lie if he isn't. To ascertain this, we could ask him if he would say yes to going left if Pierre would also say yes, which we can formulate as:<br><br>

            dit_oui(henri, dit_oui(pierre, gauche))<br><br>

            So, we have:<br><br>

            i. If Henri is the truth-teller, then Pierre is a liar. Pierre would say no to the correct answer if the correct direction is left. Henri would truthfully report Pierre's response, which is no.<br>
            ii. If Henri is a liar, then Pierre is truthful and would say yes to the correct answer. Being a liar, Henri would say the opposite.<br>
            iii. If the correct direction is to go left, the answer will be yes.<br>
            iv. If the correct direction is to go right, the answer will be no.<br><br>

            Thus, we can set:<br><br>

            t = dit_oui(henri, dit_oui(pierre, gauche))<br><br>

            This satisfies:<br><br>

            KB |= (Answer_yes(henri, t) = Go_left)<br><br>

            This proves that the traveller can ask this question to determine the correct path.<br><br>

            Finally, for c), since Go_left is a predicate and not a logical consequence of any other predicates in the KB, it can be assigned independently. Thus, we have the following:<br><br>

            i. A model where Go_left is true, meaning left is correct.<br>
            i. A model where Go_left is false, meaning right is correct.<br><br>

            Both models satisfy the KB, proving that it does not entail whether the correct direction is left or right.<br><br>

            For the second part of the exercise, the following is a diagram of the crossing problem:<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/diagram.png" height="400" width="650"><br>
                
            <font size="2">Figure 17: The crossing problem diagram</font></center><br><br>

            We can see a sequence of states and movements required to get to each of them. We could use the following FOL statements for each state:<br><br>

            <b>state (w, w, w, w):</b> West(F) ∧ West(W) ∧ West(G) ∧ West(C)<br><br>
            <b>state (e, w, e, w):</b> East(F) ∧ West(W) ∧ East(G) ∧ West(C)<br><br>
            <b>state (w, w, e, w):</b> West(F) ∧ West(W) ∧ East(G) ∧ West(C)<br><br>
            <b>state (e, w, e, e):</b> East(F) ∧ West(W) ∧ East(G) ∧ East(C)<br><br>
            <b>state (w, w, w, e):</b> West(F) ∧ West(W) ∧ West(G) ∧ East(C)<br><br>
            <b>state (e, e, w, e):</b> East(F) ∧ East(W) ∧ West(G) ∧ East(C)<br><br>
            <b>state (w, e, w, e):</b> West(F) ∧ East(W) ∧ West(G) ∧ East(C)<br><br>

            As can be seen in the solutions, the closest match to my FOL version is offered by the one written in Prolog, being closely followed by the Maude version.

            </p><br><br>


        <h2 id="unit4-seminar-prep">Unit 4 Seminar Preparation</h2>
            <p>The fourth seminar activity consisted of answering the following questions through the use of the Prolog programming language:<br><br>

            "<i>1. Prolog can be used to test the questions included in Unit 2. For example, to test exercise 1 carry out the following steps.<br><br>
                * Surf to https://swi-prolog.org<br>
                * Click on “try swi-prolog online”.<br>
                * On the SWISH page click on notebook.<br>
                * Click on Query.<br>
                * In the 'query' box enter “member(c, [a,b,c,2,3,4])”.<br>
                * Click the go (>) button - it should give the answer 'true' (I.e., c is a member of the set).<br>
                * How many of the questions in exercise 1 can you check in this way?<br><br>

                2. Read Ritchie (2002) section 8.2 (starting on pg 12). Input the facts into the SWI-SWISH page and run the queries. To do this:<br><br>
                * Click the + sign next to the word notebook.<br>
                * Choose program.<br>
                * Enter the facts (printed in the Ritchie book) into the large window.<br>
                * On the right hand side of the screen you will see a smaller window, with a “?- “ at the top corner - this is the query box.<br>
                * Enter your queries into the box then click the run button.<br>
                * Try all the queries presented in sections 8.2 and 8.3 of the Ritchie book.<br><br>

                3. Enter the Prolog version of the “crossing problem” into the SWISH program window and run it. What is the result?</i>"<br><br>

            For the first question, we can quickly verify that we can answer all questions included in exercise one from Unit 2 as they can be readily adapted to a format that Prolog can handle. Some examples of this look as follows:<br><br>

            i.a) ~P<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/prolog_1_i_a.png" height="150" width="350"><br>
                
            <font size="2">Figure 18: Exercise i.a) in Prolog, highlighting the use of "not" (\+)</font></center><br><br>

            i.c) P v Q<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/prolog_1_i_c.png" height="150" width="550"><br>
                
            <font size="2">Figure 19: Exercise i.c) in Prolog, highlighting the use of "or" (;)</font></center><br><br>

            i.f) P → (~Q)<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/prolog_1_i_f.png" height="150" width="600"><br>
                
            <font size="2">Figure 20: Exercise i.f) in Prolog, highlighting the use of "if then" (->)</font></center><br><br>
            
            iv.a) ~(P ∧ Q)<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/prolog_1_iv_a.png" height="150" width="600"><br>
                
            <font size="2">Figure 21: Exercise iv.a) in Prolog, highlighting the use of "not" and "and" (\+ and ,)</font></center><br><br>

            For the second question, reading through Ritche (2002) section 8.2 illustrates the use of facts in Prolog and how they can be used in building sophisticated programs. Inputting the facts into the SWI-SWISH page results in the following:<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/ritchie_facts.png" height="250" width="400"><br>
                
            <font size="2">Figure 22: The facts from Ritchie (2002) section 8.2. in SWI-SWISH</font></center><br><br>

            With these facts ready, we're ready to start "asking" questions. Using the queries in the same section allows us to do so, and the results are as follows:<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/ritchie_queries.png" height="550" width="400"><br>
                
            <font size="2">Figure 22: The queries from Ritchie (2002) section 8.2. in SWI-SWISH</font></center><br><br>

            Moving on to section 8.3., new facts are introduced and which result in the expansion of the information available from our queries, which now looks as follows:<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/ritchie_new_facts.png" height="450" width="400"><br>
                
            <font size="2">Figure 23: The facts from Ritchie (2002) section 8.3. in SWI-SWISH</font></center><br><br>

            Given the new facts, making inquiries on new relationships has become possible, such as the following:<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/ritchie_new_queries.png" height="350" width="400"><br>
                
            <font size="2">Figure 24: The queries from Ritchie (2002) section 8.3. in SWI-SWISH</font></center><br><br>

            Finally, for the last question, entering the Prolog version of the "crossing problem" in SWI-Prolog (as well as its dependency, <i>adts</i>) results in the following when consulting it:<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/prolog_crossing_problem.png" height="550" width="350"><br>
                
            <font size="2">Figure 25: Consulting the 'crossing problem' algorithm with the query <i>go(state(w,w,w,w), state(e,e,e,e)).</i></font></center></p><br><br>


        <h2 id="unit5-activity">Unit 5 Activity</h2>
            <p>The unit 5 activity consisted of answering the following:<br><br>

            "<i>Activity 1<br><br>
                Read the article by Bimba et al (2016) and then answer the following questions:<br><br>

                a) What are the 3 knowledge bases identified by the authors?<br>
                b) What are the differences between them?<br>
                c) How are these related to ontologies?<br><br>

            Activity 2<br><br>
                Read the article by Leydesdorff, L. (2010) and then answer the questions below:<br><br>

                a) How does the author define a 'Knowledge based economy'?<br>
                b) What is the triple helix model?<br><br>
                
            Activity 3<br><br>
                Read the Fensel et al (2000) paper then answer the following questions:<br><br>

                a) What are the components of the Onto Knowledge model/ framework?<br>
                b) What are the example use cases given for the framework?</i>"<br><br>

            For the first activity, we have the following:<br><br>

            1. a) The three linguistic bases identified are <b>linguistic knowledge</b>, which focus on language semantics (such as WordNet), <b>expert knowledge</b>, which contain domain-specific rules for problem-solving, and <b>cognitive knowledge</b>, which model human cognition by integrating linguistic and expert knowledge.<br><br>

            1. b) Linguistic knowledge bases handle semantics, while expert knowledge bases encode specialised rules and cognitive knowledge bases integrate both for adaptive reasoning.<br><br>

            1. c) Ontologies provide a structured framework for organising and sharing knowledge, which supports all three knowledge bases types.<br><br>

            For the second activity, we have:<br><br>

            2. a) Leydesdorff (2010) defines a 'knowledge-based economy' as one where <b>knowledge</b> drives innovation, economic growth, and employment.<br><br>

            2. b) The triple helix model is defined as the interaction between <b>universities</b> (knowledge generation), <b>industry</b> (application of knowledge), and <b>government</b> (policy and regulation) to foster innovation.<br><br>

            For the third activity, we have the following:<br><br>

            3. a) The components of the OntoKnowledge model are <b>ontology-based data access</b>, <b>knowledge acquisition tools</b>, <b>annotation tools</b>, and <b>inference engines</b> for reasoning and decision support.<br><br>

            3. b) Some examples include corporate knowledge management for efficient knowledge organisation, semantic search engines for more relevant search results, and e-learning systems for personalised education.</p><br><br>


        <h2 id="unit6-activity">Unit 6 Activity</h2>
            <p>The unit 6 activity consisted of answering the following:<br><br>

            "<i>Read the article by Demoly et al. (2019)<br><br>

                Reflect on the different strategies to developing ontologies. What are the benefits and drawbacks of each approach? Consider various scenarios and which methods would be suitable.</i>"<br><br>

            Developing ontologies enables shared understanding across domains, with Demoly et al. (2019) stating that different strategies offer unique benefits and drawbacks. These strategies are:<br><br> 
            
            <b>a) The top-down approach:</b> Refines broad concepts into specific ones, with benefits being structural coherence and alignment with standards, ensuring interoperability. However, it is resource-intensive and can be too abstract, making it ideal for standardized fields like medicine or law.<br><br>

            <b>b) The bottom-up approach:</b> Builds from specific data points, with benefits being practical relevance and flexibility. However, it risks fragmentation and scalability issues, making it suited for data-driven fields lacking predefined structures.<br><br>

            <b>c) The middle-out approach:</b> Expands from core concepts, with benefits being balance between coherence and adaptability and efficiency. However, it requires careful coordination to avoid redundancy, making it ideal for domains with well-defined key concepts.<br><br>

            <b>d) The automated approach:</b> extracts ontology structures using AI, with benefits being scalability and speed. However, it may lack accuracy and struggle with contextual nuances, making it best for large-scale data extraction.<br><br>

            Choosing the right approach depends on domain complexity, data availability, and project goals, with hybrid methods often providing the best balance.</p><br><br>

        
        <h2 id="reflective-piece1">Mid-Module Reflective Piece</h2>
            <p>The "Knowledge Representation and Reasoning" module has deepened my understanding of how AI structures and processes knowledge. Engaging with logic programming, first-order logic (FOL), and ontologies has strengthened my problem-solving skills. The crossing problem and truth table exercises demonstrated how structured reasoning supports AI decision-making. Comparing ontology development strategies—top-down, bottom-up, middle-out, and automated—highlighted their strengths and trade-offs, reinforcing the importance of structured knowledge in AI transparency.<br><br>

            Beyond technical learning, collaborative discussions refined my ability to articulate ideas and critically evaluate different perspectives. Engaging with peers helped me improve my arguments and recognize diverse viewpoints. This iterative learning approach mirrored real-world research, where feedback and discourse drive progress. Overall, this module has significantly enhanced my logical reasoning and symbolic AI skills, preparing me for more advanced applications in AI research and knowledge-based systems.</p><br><br>


        <h2 id="assess1">Assessment: Case Study Review</h2>
            <p>The first assessment involved coming up with a report discussing the paper 'A curated ontology-based large-scale knowledge graph of artificial intelligence tasks and benchmarks', by Blagec et al. (2022). It introduces the Intelligence Task Ontology (ITO) framework and addresses the growing complexity of AI research, focusing on task classification, benchmarking, and performance metrics within a structured, ontology-based framework. My approach focused on discussing the paper through the following topics:<br><br> 
            
            a) <b>Background and objectives</b>, which provided a definition of ITO, the desiderata for its creation, and what were this approach's objectives;<br><br>

            b) <b>Methodology</b>, which provided an in-depth analysis of ITO's methodology, such as its use of knowledge graphs and the way it models AI tasks;<br><br>

            c) <b>Applications and impact</b>, where areas of application for ITO and the impact behind this approach, such as in explainable AI and open science, were elaborated upon;<br><br>

            d) <b>Strengths and weaknesses</b>, where this approach's major advantages and flaws were discussed and exemplified to provide a critical, but fair, analysis;<br><br>

            e) <b>Conclusion</b>, where possible next steps for this framework are laid out and could help in it becoming more widely known and used in AI research.<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/case_study_snippet.png" height="600" width="600"><br>
                
            <font size="2">Figure 26: A snippet of the case study report, focusing on the "Applications and impact" section</font></center></p><br><br>
            

            <h3 id="assess1-feedback"><br>Tutor feedback</h3>
                <p>Dr. Samuel Danso's feedback allowed me to see the flaws in my report, such as the lack of reference-backed examples. His response was instrumental in allowing me to improve my report for the next assignment, and was as follows<br><br>
                
                <center><img src="img/knowledge_repr_and_reasoning/tutor_feedback_assign1.png" height="550" width="1000"><br>
                
                <font size="2">Figure 27: Tutor feedback on the first assignment</font></center><br><br>
                
                </p><br><br>


        <h2 id="unit8-activity">Unit 8 Activity</h2>
            <p>The unit 8 activity consisted of doing the following:<br><br>

            "<i>1. Work through a practical example by following Chapter 4 of Debellis, M. (2021) A Practical Guide to Building OWL Ontologies Using Protégé 5.5 and Plugins.<br>
            2. Create an ontology following the steps outlined in Exercises 1-7.</i>"<br><br>

            In exercise 1, Debelis (2021) goes through the several important steps that are required when configuring Protégé, such as which tab should be active, how to create a new ontology project, and which format is ideal for saving the work produced in the system. 
            
            <center><img src="img/knowledge_repr_and_reasoning/protege_uri.png" height="300" width="800"><br>
                
            <font size="2">Figure 28: The URI of the tutorial Protégé project</font></center><br><br>

            Subsequently, in exercise 2, preferences are defined for new entities and rendering, with "Render by entity IRI short name (ID)" is selected as the default entity rendering method.<br><br>
             
            <center><img src="img/knowledge_repr_and_reasoning/protege_renderer_tab.png" height="400" width="700"><br>
                
            <font size="2">Figure 29: The renderer tab in Protégé, highlighting the new preferences</font></center><br><br>

            In exercise 3, an overview is given on how to add comment annotations to ontologies by using the <i>rdfs:comment</i> annotation. Additionally, creating named classes, the main building blocks of OWL-based ontologies, is introduced here.<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/protege_named_classes.png" height="300" width="800"><br>
                
            <font size="2">Figure 30: The entities tab in Protégé, showing the "Pizza" entity</font></center><br><br>

            In exercise 4, the creation of classes is expanded upon and additional classes are created, such as "PizzaTopping" and "PizzaBase", both of which sit under "owl:Thing" alongside the previously created "Pizza" class. Additionally, a brief introduction is given to reasoners in Protégé, which essentially function as class consistency verifiers.<br><br>
            
            <center><img src="img/knowledge_repr_and_reasoning/protege_more_classes.png" height="300" width="800"><br>
                
            <font size="2">Figure 31: The entities tab in Protégé, showing the new "PizzaTopping" and "PizzaBase" entities</font></center><br><br>

            Afterwards, in exercise 5, the reasoner concept is expanded upon as the Pellet Reasoner, a plugin, is installed and started. This will verify if the classes are consistent, and will run fairly quickly given the ontology is very small. Additionally, a brief commentary is provided on disjoint classes, a concept where an individual cannot be an instance of more than one of those classes.<br><br>
            
            <center><img src="img/knowledge_repr_and_reasoning/protege_reasoner_prefs.png" height="600" width="700"><br>
                
            <font size="2">Figure 32: The reasoner preferences tab in Protégé</font></center><br><br>

            In exercise 6, the concept of disjoint classes is applied on the existing "PizzaTopping", "PizzaBase", and "Pizza" classes. This section also briefly introduces the class hierarchy creation section, showcasing its capability to create multiple classes at once.<br><br>
            
            <center><img src="img/knowledge_repr_and_reasoning/protege_disjoint.png" height="300" width="800"><br>
                
            <font size="2">Figure 33: The description of the "Pizza" class in Protégé, showing the classes it's disjoint with</font></center><br><br>

            Finally, exercise 7 consists of using the class hierarchy creation functionality to create subclasses of "PizzaBase", resulting in the creation of "DeepPanBase" and "ThinAndCrispyBase". The creation of a more interesting hierarchy is also teased in this exercise.<br><br>
            
            <center><img src="img/knowledge_repr_and_reasoning/protege_hierarchy.png" height="500" width="700"><br>
                
            <font size="2">Figure 34: The new subclasses of "PizzaBase" in Protégé, which were created with the class hierarchy creation functionality</font></center></p><br><br>


        <h2 id="colab-2">Collaborative Learning Discussion 2</h2>
            <p>The second collaborative learning discussion served as a way for students to further hone their argumentative skills by discussing the following:<br><br>
            
            "<i>Kalibatiene & Vasilecas (2011) posit that 'An ontology is a formal, explicit specification of a shared conceptualization'.<br><br>

                Based on this definition, which language do you believe is the most useful to express ontologies that can be utilised by software agents on the WWW: KIF, OWL2, RDF or OWL-lite?"</i><br><br>

            Students were required to create an initial post and, then, address at least 3 of their peers' submissions before creating a summary post. This final entry would serve as an evolved version of a student's initial post, incorporating peer responses and directly addressing them by either agreeing or not and providing the reasons for either case. My initial post, "Ontology Languages: The Case for OWL 2", was as follows:<br><br>
            
            <center><img src="img/knowledge_repr_and_reasoning/initial_post_2.png" height="600" width="1150"><br>

            <font size="2">Figure 35: My initial post in the second collaborative learning discussion forum</font></center></p><br><br>

            
            <h3 id="colab-21"><br>Peer feedback</h3>
                <p>The peer responses from James Adams, Zhu Zhang, and Jaafar El Komati were instrumental in building upon my initial post. For James, his response was as follows:<br><br>
                
                <center><img src="img/knowledge_repr_and_reasoning/james_response.png" height="550" width="1100"><br>

                <font size="2">Figure 2: James' peer response to my initial post</font></center><br><br></font></center><br><br>
                
                As for Zhu, his response was:<br><br>
                
                <center><img src="img/knowledge_repr_and_reasoning/zhu_response.png" height="350" width="950"><br>

                <font size="2">Figure 3: Zhu's peer response to my initial post</font></center></p><br><br>

                Finally, Jaafar's response was:<br><br>
                
                <center><img src="img/knowledge_repr_and_reasoning/jaafar_response.png" height="500" width="1100"><br>

                <font size="2">Figure 4: Jaafar's peer response to my initial post</font></center></p><br><br>


            <h3 id="colab-22"><br>Summary post</h3>
                <p>My initial entry was significantly enhanced by my peers' feedback. Their comments were addressed by my summary post, which was as follows:<br><br>

                <center><img src="img/knowledge_repr_and_reasoning/summary_post_disc1.png" height="600" width="1100"><br>
                
                <font size="2">Figure 5: My summary post in the first discussion forum</font></center></p><br><br>


        <h2 id="unit10-activity">Unit 10 Activity</h2>
            <p>The unit 10 activity consisted of doing the following:<br><br>

            "<i>Read section 4.1.2 onwards of Debellis, M. (2021) A Practical Guide to Building OWL Ontologies Using Protégé 5.5 and Plugins.<br><br>

            Then work through exercises 22-26.</i>"<br><br>

            In exercise 22, Debelis, M. (2021) explores the creation of defined classes in Protégé by using the "VegetarianPizza" class as an example, outlining its usefulness of such a concept and potential pitfalls to be aware of, such as using intersections instead of unions. The class is subsequently transformed into a defined class.<br><br>

            <center><img src="img/knowledge_repr_and_reasoning/protege_vegetarian_pizza.png" height="450" width="1100"><br>
                
            <font size="2">Figure 39: The "VegetarianPizza" subclass as a defined class</font></center><br><br>

            In exercise 23, closure axioms are introduced and explored via the "hasTopping" property for the "MargheritaPizza" and "SohoPizza" classes. The concept of enumerated classes, which are powerful tools in object-oriented programming (OOP), is also touched upon here and which OWL as an ontology language borrows extensively from.<br><br> 
            
            <center><img src="img/knowledge_repr_and_reasoning/protege_closure_axioms.png" height="550" width="1100"><br>
                
            <font size="2">Figure 40: The use of closure axioms on the "MargheritaPizza" and "SohoPizza" classes</font></center><br><br>

            In exercise 24, an enumerated class is used to represent the spiciness of a pizza through three individuals: "Hot", "Medium", and "Mild". The process is finalised by the reasoner after it's supplied the DL axiom <i>{Hot, Medium, Mild}</i>, which results all individuals becoming instances of Spiciness.<br><br> 

            <center><img src="img/knowledge_repr_and_reasoning/protege_enum_class.png" height="550" width="1100"><br>
                
            <font size="2">Figure 41: The use of closure axioms on the "MargheritaPizza" and "SohoPizza" classes</font></center><br><br>

            In exercise 25, the property "hasSpiciness" is created and used. This property is applied to the "JalapenoPepperTopping" with the DL axiom <i>hasSpiciness value Hot</i>, and is, afterwards, used to create a new "Pizza" subclass for spicy pizzas, "SpicyPizza", which is converted into a defined class afterwards.<br><br> 

            <center><img src="img/knowledge_repr_and_reasoning/protege_spiciness.png" height="550" width="1100"><br>
                
            <font size="2">Figure 42: The new "JalapenoPepperTopping" subclass' information and the "SpicyPizza" subclass</font></center><br><br>

            In exercise 26, the subclass "InterestingPizza" is created, which is comprised of at least three distinct toppings. Because of this definition, pizzas that are of the same type will be associated with "InterestingPizza" by the reasoner.<br><br> 

            <center><img src="img/knowledge_repr_and_reasoning/protege_interesting_pizza.png" height="550" width="1100"><br>
                
            <font size="2">Figure 43: The "InterestingPizza" subclass</font></center><br><br>


        <h2 id="assess2">Assessment: AI Application Solution</h2>
            <p>The second assignment was a direct continuation of the previous one. In this report, we had to come up with an experiment using one of the previously defined three key areas to demonstrate that our AI claims were achievable. My experiment focused on identifying fraudulent credit card transactions via machine learning (ML) algorithms, more specifically supervised learning approaches. To make the experiment as organised and reproducible as possible, the CRISP-DM process was employed.<br><br>

            <center><img src="https://www.sv-europe.com/wp-content/uploads/2016/04/Screenshot-2016-04-20-11.58.54.png" height="500" width="600"><br>
                
            <font size="2">Figure 10: The CRISP-DM process (<a href="https://www.sv-europe.com/crisp-dm-methodology/">Smart Vision Europe</a>)</font></center><br><br>

            As such, the experiment focused on business understanding, data understanding and preparation, modelling and evaluation. Deployment was not addressed as it was out of scope, but recommendations were made when it comes to monitoring data and model drift.<br><br>
            
            When it comes to the candidate models that were considered, the following research-backed options were evaluated:<br><br>
            
            a) J48 (decision tree);<br> 
            b) Naive Bayes;<br>
            c) Random forest;<br>
            d) Logistic regression;<br>
            e) Multilayer perceptron.<br><br>
            
            The models were trained and evaluated using stratified k-fold cross-validation, and the best-fit model underwent a limited hyperparameter tuning process to ascertain if it could be improved even further. 
            
            </p><br><br>
                

            <h3 id="assess2-feedback"><br>Tutor feedback</h3>
                <p>Dr. Samuel Danso's feedback showed that my report's overall structure had greatly improved, although there was room for further improvement when it came to providing more details on what was being done. His feedback was as follows:<br><br>
                
                <center><img src="img/understanding_ai/tutor_feedback_assign2.png" height="350" width="1200"><br>
                
                <font size="2">Figure 10: Tutor feedback on the second assignment</font></center><br><br>
                
                </p><br><br>
        
    
        <h2 id="assess-outcome">Learning Outcome: Soft and Hard Skills in Business</h2>
            <p>The assignments were incredibly useful in demonstrating to students that, in industry (and even in academia), hard skills (such as programming) alone are not enough. Soft skills (such as communication) will always be required, especially for the following reasons:<br><br><br>
            
            a) <b>Technical barrier:</b> Business-oriented individuals will, in most cases, not have the technical depth and expertise that, for instance, a data scientist possesses. Communication must be levelled out so that they can understand what is being done and why;<br><br>

            b) <b>Politics:</b> Internal politics, such as department rivalries, must be navigated so that technical projects are not affected, and the only way of achieving this is by having a clear and direct line of communication, as well as good negotiating skills;<br><br>

            c) <b>Collaboration:</b> Technical projects often involve multiple teams with diverse expertise. Effective communication ensures that all team members are on the same page, which is essential for the successful completion of projects;<br><br>

            d) <b>Conflict resolution:</b> Conflicts are inevitable in any collaborative setting. Having strong interpersonal skills will prove instrumental in resolving conflicts amicably, ensuring that the focus remains on the project goals.

            </p><br><br>


        <h2 id="reflection">Reflective Piece</h2>
            <p>The "Understanding Artificial Intelligence" module was instrumental in not only introducing students to the world of AI, but also in enabling us to engage in meaningful and reference-backed discussions and conducting independent experiments. All of the tasks in the module required us to think independently and critically, evaluating all possible actions and outcomes in an impartial manner and choosing the best path based on the available constraints. The module was designed in such a way that it allowed even newcomers to the field to understand how complex implementing and maintaining AI systems is, both from technical and business perspectives.<br><br> 
            
            Additionally, the legal, ethical and professional principles behind AI are vast and were carefully addressed in the module, allowing students to grasp just how large of an impact this technology is making in modern society. This field is evolving in such a rapid pace that indiscriminate usage, both by individuals and companies alike, will result in substantial damage should it not be monitored and regulated effectively. Balancing this regulatory process will be important in allowing innovative creations to help shape the future of AI while blocking nefarious practices that may arise out of it.</p>
    </div>
  </div>
</div>
</main>

<script src="../js/pgConfgMarkdown.js"></script>